{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01. Loads the data and creates a Pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"breast_cancer_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02. Prints the number of features in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id\n",
      "diagnosis\n",
      "radius_mean\n",
      "texture_mean\n",
      "perimeter_mean\n",
      "area_mean\n",
      "smoothness_mean\n",
      "compactness_mean\n",
      "concavity_mean\n",
      "concave points_mean\n",
      "symmetry_mean\n",
      "fractal_dimension_mean\n",
      "radius_se\n",
      "texture_se\n",
      "perimeter_se\n",
      "area_se\n",
      "smoothness_se\n",
      "compactness_se\n",
      "concavity_se\n",
      "concave points_se\n",
      "symmetry_se\n",
      "fractal_dimension_se\n",
      "radius_worst\n",
      "texture_worst\n",
      "perimeter_worst\n",
      "area_worst\n",
      "smoothness_worst\n",
      "compactness_worst\n",
      "concavity_worst\n",
      "concave points_worst\n",
      "symmetry_worst\n",
      "fractal_dimension_worst\n",
      "Unnamed: 32\n",
      "\n",
      "#Number of features:  33\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for col in dataset.columns:\n",
    "    print(col)\n",
    "    count+=1\n",
    "    \n",
    "print(\"\\n#Number of features: \", count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03. Number of Samples in each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "B    357\n",
       "M    212\n",
       "Name: diagnosis, dtype: int64"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['diagnosis'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                           0\n",
       "diagnosis                    0\n",
       "radius_mean                  0\n",
       "texture_mean                 0\n",
       "perimeter_mean               0\n",
       "area_mean                    0\n",
       "smoothness_mean              0\n",
       "compactness_mean             0\n",
       "concavity_mean               0\n",
       "concave points_mean          0\n",
       "symmetry_mean                0\n",
       "fractal_dimension_mean       0\n",
       "radius_se                    0\n",
       "texture_se                   0\n",
       "perimeter_se                 0\n",
       "area_se                      0\n",
       "smoothness_se                0\n",
       "compactness_se               0\n",
       "concavity_se                 0\n",
       "concave points_se            0\n",
       "symmetry_se                  0\n",
       "fractal_dimension_se         0\n",
       "radius_worst                 0\n",
       "texture_worst                0\n",
       "perimeter_worst              0\n",
       "area_worst                   0\n",
       "smoothness_worst             0\n",
       "compactness_worst            0\n",
       "concavity_worst              0\n",
       "concave points_worst         0\n",
       "symmetry_worst               0\n",
       "fractal_dimension_worst      0\n",
       "Unnamed: 32                569\n",
       "dtype: int64"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.dropna(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.drop(\"id\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04. Randomly splits the dataset into Training and Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.drop(\"diagnosis\", axis=1)\n",
    "y = dataset[\"diagnosis\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 05. Train different classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "def models(X_train,Y_train):\n",
    "    #Logistic Regression\n",
    "    modelLRC = LogisticRegression()\n",
    "    modelLRC.fit(X_train, Y_train)\n",
    "    \n",
    "    #KNN\n",
    "    modelKNNC = KNeighborsClassifier(n_neighbors = 3)\n",
    "    modelKNNC.fit(X_train, Y_train)\n",
    "    \n",
    "    #SVM\n",
    "    modelSVMC = SVC(kernel = 'linear')\n",
    "    modelSVMC.fit(X_train, Y_train)\n",
    "    \n",
    "    #Decision Tree\n",
    "    modelDTC = DecisionTreeClassifier()\n",
    "    modelDTC.fit(X_train, Y_train)\n",
    "    \n",
    "    #Naive Bayes\n",
    "    modelNBC = GaussianNB()\n",
    "    modelNBC.fit(X_train, Y_train)\n",
    "    \n",
    "    return modelLRC, modelKNNC, modelSVMC, modelDTC, modelNBC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 06.  Predict the class for each test sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0\n",
      "['M' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'M' 'B' 'M' 'B' 'M'\n",
      " 'M' 'M' 'M' 'M' 'B' 'B' 'M' 'B' 'B' 'M' 'B' 'M' 'B' 'M' 'B' 'M' 'B' 'M'\n",
      " 'B' 'M' 'B' 'M' 'M' 'B' 'M' 'B' 'M' 'M' 'B' 'B' 'B' 'M' 'M' 'M' 'M' 'B'\n",
      " 'B' 'B' 'B' 'B' 'B' 'M' 'M' 'M' 'B' 'B' 'M' 'B' 'M' 'M' 'M' 'B' 'M' 'M'\n",
      " 'B' 'B' 'M' 'B' 'B' 'B' 'B' 'B' 'M' 'M' 'M' 'B' 'M' 'B' 'B' 'B' 'M' 'M'\n",
      " 'B' 'M' 'M' 'M' 'B' 'B' 'M' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'M' 'B' 'M' 'B'\n",
      " 'M' 'M' 'B' 'M' 'M' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'M' 'B' 'M' 'B'\n",
      " 'M' 'B' 'B' 'B' 'M' 'B' 'B' 'B' 'B' 'B' 'B' 'M' 'M' 'B' 'B' 'B' 'M' 'B'\n",
      " 'B' 'M' 'B' 'M' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'M' 'B' 'M' 'B' 'M' 'M' 'B'\n",
      " 'B' 'M' 'B' 'M' 'M' 'M' 'B' 'B' 'B']\n",
      "\n",
      "Model 1\n",
      "['M' 'B' 'B' 'M' 'B' 'B' 'B' 'B' 'B' 'B' 'M' 'B' 'B' 'M' 'M' 'M' 'B' 'M'\n",
      " 'M' 'M' 'M' 'M' 'B' 'B' 'M' 'B' 'B' 'B' 'B' 'M' 'B' 'M' 'B' 'M' 'B' 'M'\n",
      " 'B' 'M' 'B' 'M' 'M' 'B' 'M' 'B' 'M' 'M' 'B' 'B' 'B' 'M' 'M' 'B' 'M' 'B'\n",
      " 'B' 'B' 'B' 'B' 'B' 'M' 'M' 'M' 'B' 'B' 'M' 'B' 'M' 'M' 'M' 'B' 'B' 'M'\n",
      " 'B' 'B' 'M' 'B' 'B' 'B' 'B' 'B' 'M' 'M' 'M' 'B' 'M' 'B' 'B' 'B' 'M' 'M'\n",
      " 'B' 'M' 'B' 'B' 'B' 'B' 'M' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'M' 'B' 'M' 'M'\n",
      " 'M' 'M' 'B' 'M' 'M' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'M' 'B'\n",
      " 'B' 'B' 'B' 'B' 'M' 'B' 'B' 'B' 'B' 'B' 'B' 'M' 'M' 'B' 'B' 'B' 'M' 'B'\n",
      " 'B' 'M' 'M' 'M' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'M' 'M' 'B'\n",
      " 'B' 'M' 'B' 'M' 'M' 'M' 'B' 'B' 'B']\n",
      "\n",
      "Model 2\n",
      "['M' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'M' 'B' 'B' 'B' 'B' 'M' 'B' 'M'\n",
      " 'M' 'M' 'M' 'M' 'B' 'B' 'B' 'B' 'B' 'M' 'B' 'M' 'B' 'M' 'B' 'M' 'B' 'M'\n",
      " 'B' 'M' 'B' 'M' 'M' 'B' 'M' 'B' 'M' 'M' 'B' 'B' 'B' 'M' 'M' 'M' 'M' 'B'\n",
      " 'B' 'B' 'B' 'B' 'B' 'M' 'M' 'M' 'B' 'B' 'M' 'B' 'M' 'M' 'M' 'B' 'M' 'M'\n",
      " 'B' 'B' 'M' 'B' 'B' 'B' 'B' 'B' 'M' 'M' 'M' 'B' 'M' 'B' 'B' 'B' 'M' 'M'\n",
      " 'B' 'M' 'M' 'M' 'B' 'B' 'M' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'M' 'B' 'M' 'B'\n",
      " 'M' 'M' 'B' 'M' 'M' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'M' 'B' 'M' 'B'\n",
      " 'B' 'B' 'B' 'B' 'M' 'B' 'B' 'B' 'B' 'B' 'B' 'M' 'M' 'B' 'B' 'B' 'M' 'B'\n",
      " 'B' 'M' 'B' 'M' 'B' 'B' 'B' 'M' 'B' 'B' 'B' 'M' 'B' 'M' 'B' 'M' 'M' 'B'\n",
      " 'B' 'M' 'B' 'M' 'M' 'M' 'B' 'B' 'B']\n",
      "\n",
      "Model 3\n",
      "['M' 'B' 'B' 'B' 'B' 'M' 'B' 'B' 'B' 'B' 'M' 'B' 'B' 'M' 'B' 'M' 'B' 'M'\n",
      " 'M' 'M' 'M' 'M' 'B' 'B' 'M' 'B' 'B' 'M' 'B' 'M' 'B' 'M' 'B' 'M' 'B' 'M'\n",
      " 'B' 'M' 'B' 'M' 'B' 'B' 'M' 'B' 'B' 'M' 'B' 'B' 'B' 'M' 'M' 'M' 'M' 'B'\n",
      " 'B' 'B' 'M' 'B' 'M' 'M' 'M' 'M' 'B' 'B' 'M' 'B' 'M' 'M' 'M' 'B' 'B' 'M'\n",
      " 'B' 'B' 'M' 'B' 'B' 'B' 'B' 'B' 'M' 'M' 'M' 'B' 'M' 'B' 'B' 'B' 'M' 'M'\n",
      " 'B' 'M' 'B' 'M' 'B' 'B' 'M' 'B' 'B' 'B' 'B' 'B' 'B' 'M' 'M' 'B' 'M' 'B'\n",
      " 'M' 'B' 'B' 'M' 'M' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'M' 'B' 'M' 'M'\n",
      " 'M' 'B' 'B' 'B' 'M' 'B' 'B' 'B' 'B' 'B' 'B' 'M' 'M' 'B' 'B' 'B' 'M' 'B'\n",
      " 'B' 'M' 'B' 'M' 'B' 'B' 'B' 'M' 'B' 'M' 'B' 'M' 'B' 'B' 'B' 'M' 'M' 'B'\n",
      " 'B' 'M' 'B' 'M' 'M' 'M' 'B' 'B' 'B']\n",
      "\n",
      "Model 4\n",
      "['M' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'M' 'B' 'B' 'M' 'M' 'M' 'B' 'M'\n",
      " 'M' 'M' 'M' 'M' 'B' 'B' 'M' 'B' 'B' 'M' 'B' 'M' 'B' 'M' 'B' 'M' 'B' 'M'\n",
      " 'B' 'M' 'B' 'M' 'B' 'B' 'M' 'B' 'M' 'M' 'B' 'B' 'B' 'M' 'M' 'M' 'M' 'B'\n",
      " 'B' 'B' 'B' 'B' 'B' 'M' 'M' 'M' 'B' 'B' 'M' 'B' 'M' 'M' 'M' 'B' 'B' 'M'\n",
      " 'B' 'B' 'M' 'B' 'B' 'B' 'B' 'B' 'M' 'M' 'M' 'B' 'M' 'B' 'B' 'B' 'M' 'M'\n",
      " 'B' 'B' 'B' 'M' 'B' 'B' 'M' 'M' 'B' 'B' 'B' 'B' 'B' 'B' 'M' 'B' 'M' 'B'\n",
      " 'B' 'M' 'B' 'M' 'M' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'M' 'B' 'M' 'B'\n",
      " 'B' 'B' 'B' 'B' 'M' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'M' 'B' 'B' 'B' 'M' 'B'\n",
      " 'B' 'M' 'B' 'M' 'B' 'B' 'B' 'M' 'M' 'B' 'B' 'M' 'B' 'B' 'B' 'M' 'M' 'B'\n",
      " 'B' 'M' 'B' 'M' 'M' 'M' 'B' 'B' 'B']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(model)):\n",
    "    print('Model', i)\n",
    "    prediction = model[i].predict(X_test)\n",
    "    print(prediction)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 07. Measure the accuracy of each classifier and compare them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelLRC = LogisticRegression()\n",
    "modelKNNC = KNeighborsClassifier(n_neighbors = 3)\n",
    "modelSVMC = SVC(kernel = 'linear')\n",
    "modelDTC = DecisionTreeClassifier()\n",
    "modelNBC = GaussianNB()\n",
    "    \n",
    "modelLRC.fit(X_train, y_train)\n",
    "modelKNNC.fit(X_train, y_train)\n",
    "modelSVMC.fit(X_train, y_train)\n",
    "modelDTC.fit(X_train, y_train)\n",
    "modelNBC.fit(X_train, y_train)\n",
    "\n",
    "LR = modelLRC.score(X_train, y_train)*100\n",
    "KNN = modelKNNC.score(X_train, y_train)*100\n",
    "SVM = modelSVMC.score(X_train, y_train)*100\n",
    "DT = modelDTC.score(X_train, y_train)*100\n",
    "NB = modelNBC.score(X_train, y_train)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model : 0\n",
      "[[103   5]\n",
      " [  1  62]]\n",
      "\n",
      "Model : 1\n",
      "[[101   7]\n",
      " [  7  56]]\n",
      "\n",
      "Model : 2\n",
      "[[103   5]\n",
      " [  2  61]]\n",
      "\n",
      "Model : 3\n",
      "[[98 10]\n",
      " [ 4 59]]\n",
      "\n",
      "Model : 4\n",
      "[[101   7]\n",
      " [  6  57]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(model)):\n",
    "    cnf_matrix = confusion_matrix(y_test, model[i].predict(X_test))\n",
    "    print('Model :', i)\n",
    "    print(cnf_matrix)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Accuracy chart: \n",
      "\n",
      "[0]Logistic Regression Training Accuracy: 95.7286432160804\n",
      "[1]K Nearest Neighbor Training Accuracy 95.22613065326632\n",
      "[2]Support Vector Machine Training Accuracy: 96.4824120603015\n",
      "[3]Decision Tree Training Accuracy: 100.0\n",
      "[4]Naive Bayes Training Accuracy: 94.22110552763819\n"
     ]
    }
   ],
   "source": [
    "print('#Accuracy chart: ')\n",
    "print()\n",
    "print('[0]Logistic Regression Training Accuracy:', LR)\n",
    "print('[1]K Nearest Neighbor Training Accuracy', KNN)\n",
    "print('[2]Support Vector Machine Training Accuracy:', SVM)\n",
    "print('[3]Decision Tree Training Accuracy:', DT)\n",
    "print('[4]Naive Bayes Training Accuracy:', NB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree has highest accuracy:  100.0\n"
     ]
    }
   ],
   "source": [
    "if((LR>SVM) and (LR>KNN) and (LR>DT) and (LR>NB)) :\n",
    "    print(\"Logistic Regression has highest accuracy: \", LR)\n",
    "    \n",
    "elif((KNN>SVM) and (KNN>LR) and (KNN>DT) and (KNN>NB)):\n",
    "    print(\"K-Nearest Neighbor has highest accuracy: \", KNN)\n",
    "    \n",
    "elif((SVM>LR) and (SVM>KNN) and (SVM>DT) and (SVM>NB)):\n",
    "    print(\"Support Vector Machine has highest accuracy: \", SVM)\n",
    "    \n",
    "elif((DT>LR) and (DT>KNN) and (DT>SVM) and (DT>NB)):\n",
    "    print(\"Decision Tree has highest accuracy: \", DT)\n",
    "\n",
    "else:\n",
    "    print(\"Naive Bayes has highest accuracy: \", NB)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
